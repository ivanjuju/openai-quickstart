{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 安装依赖包"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install scipy tenacity tiktoken termcolor openai requests pandas pypinyin"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import requests\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 定义工具函数\n",
    "\n",
    "首先，让我们定义一些用于调用聊天完成 API 的实用工具，并维护和跟踪对话状态。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 使用了retry库，指定在请求失败时的重试策略。\n",
    "# 这里设定的是指数等待（wait_random_exponential），时间间隔的最大值为40秒，并且最多重试3次（stop_after_attempt(3)）。\n",
    "# 定义一个函数chat_completion_request，主要用于发送 聊天补全 请求到OpenAI服务器\n",
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, functions=None, function_call=None, model=GPT_MODEL):\n",
    "\n",
    "    # 设定请求的header信息，包括 API_KEY\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
    "    }\n",
    "\n",
    "    # 设定请求的JSON数据，包括GPT 模型名和要进行补全的消息\n",
    "    json_data = {\"model\": model, \"messages\": messages}\n",
    "\n",
    "    # 如果传入了functions，将其加入到json_data中\n",
    "    if functions is not None:\n",
    "        json_data.update({\"functions\": functions})\n",
    "\n",
    "    # 如果传入了function_call，将其加入到json_data中\n",
    "    if function_call is not None:\n",
    "        json_data.update({\"function_call\": function_call})\n",
    "\n",
    "    # 尝试发送POST请求到OpenAI服务器的chat/completions接口\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "        # 返回服务器的响应\n",
    "        return response\n",
    "\n",
    "    # 如果发送请求或处理响应时出现异常，打印异常信息并返回\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from urllib.parse import urlencode\n",
    "\n",
    "baidu_key = os.getenv(\"BAIDU_KEY\")\n",
    "\n",
    "# 定义天气的请求\n",
    "@retry(wait=wait_random_exponential(multiplier=2, max=10), stop=stop_after_attempt(3))\n",
    "def weather_request(district_id):\n",
    "    base_url = 'https://api.map.baidu.com/weather/v1/'\n",
    "    params = {\n",
    "        'district_id': district_id,\n",
    "        'ak': baidu_key,\n",
    "        'output': 'json',\n",
    "        'data_type': 'now'\n",
    "    }\n",
    "\n",
    "    url = f\"{base_url}?{urlencode(params)}\"\n",
    "\n",
    "    # 尝试发送POST请求到OpenAI服务器的chat/completions接口\n",
    "    try:\n",
    "        response = ast.literal_eval(requests.get(url).text)\n",
    "        if response[\"status\"] != 0:\n",
    "            raise Exception(response[\"message\"])\n",
    "        # 返回服务器的响应\n",
    "        location = response[\"result\"][\"location\"]\n",
    "        weather = response[\"result\"][\"now\"]\n",
    "        c_name = location[\"country\"]\n",
    "        c_name += location[\"city\"] if location[\"province\"] == location[\"city\"] else location[\"province\"] + location[\"city\"]\n",
    "        return f\"{c_name + location['name']} 的天气情况：\\n\" \\\n",
    "               f\"天气：{weather['text']}\\n\" \\\n",
    "               f\"温度(摄氏度)：{weather['temp']}\\n\" \\\n",
    "               f\"湿度：{weather['rh']}\\n\" \\\n",
    "               f\"风级：{weather['wind_dir'] + weather['wind_class']}\\n\"\n",
    "\n",
    "    # 如果发送请求或处理响应时出现异常，打印异常信息并返回\n",
    "    except Exception as e:\n",
    "        print(\"Unable to fetch location weather\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国北京市北京 的天气情况：\n",
      "天气：中雨\n",
      "温度(摄氏度)：26\n",
      "湿度：98\n",
      "风级：东风2级\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(weather_request(110100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 定义一个函数pretty_print_conversation，用于打印消息对话内容\n",
    "def pretty_print_conversation(messages):\n",
    "\n",
    "    # 为不同角色设置不同的颜色\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "    }\n",
    "\n",
    "    # 遍历消息列表\n",
    "    for message in messages:\n",
    "\n",
    "        # 如果消息的角色是\"system\"，则用红色打印“content”\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "\n",
    "        # 如果消息的角色是\"user\"，则用绿色打印“content”\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "\n",
    "        # 如果消息的角色是\"assistant\"，并且消息中包含\"function_call\"，则用蓝色打印\"function_call\"\n",
    "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant[function_call]: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
    "\n",
    "        # 如果消息的角色是\"assistant\"，但是消息中不包含\"function_call\"，则用蓝色打印“content”\n",
    "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant[content]: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "\n",
    "        # 如果消息的角色是\"function\"，则用品红色打印“function”\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import traceback\n",
    "# 提供将城市名字对应到英文名称\n",
    "from pypinyin import lazy_pinyin\n",
    "from functools import wraps\n",
    "import re\n",
    "\n",
    "def log_error(func):\n",
    "    @wraps(func)\n",
    "    def execute(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(f\"错误信息：{e}, {traceback.format_exc()}\")\n",
    "    return execute\n",
    "\n",
    "\n",
    "# unicode编码范围判断是否包含中文\n",
    "def contains_chinese(input_str):\n",
    "    pattern = re.compile(r'[\\u4e00-\\u9fff]')\n",
    "    return bool(pattern.search(input_str))\n",
    "\n",
    "@log_error\n",
    "def translate_city_to_eg(city_name):\n",
    "    # 判断是否为中文\n",
    "    if not contains_chinese(city_name):\n",
    "        return city_name\n",
    "    # 包含中文进行拼音转化\n",
    "    result = lazy_pinyin(city_name)\n",
    "    city_name_eg = ''\n",
    "    for part in result:\n",
    "        city_name_eg += part.title()\n",
    "    return city_name_eg\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(translate_city_to_eg(\"上海市\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 准备城市地址，用于查询天气\n",
    "df = pd.read_csv(\"data/weather_district_id.csv\")\n",
    "df[\"province_eg\"] = df[\"province\"].apply(translate_city_to_eg)\n",
    "df[\"city_eg\"] = df[\"city\"].apply(translate_city_to_eg)\n",
    "df[\"district_eg\"] = df[\"district\"].apply(translate_city_to_eg)\n",
    "df[\"combined\"] = (\n",
    "    \"China; \" + df.province_eg.str.strip() +\n",
    "    \"; \" + df.city_eg.str.strip() +\n",
    "    \"; \" + df.district_eg.str.strip()\n",
    ")\n",
    "df.drop(\"province_eg\", axis=1, inplace=True)\n",
    "df.drop(\"city_eg\", axis=1, inplace=True)\n",
    "df.drop(\"district_eg\", axis=1, inplace=True)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding\n",
    "# 将城市信息进行embedding，存入到df[\"embedding\"]中\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "df[\"embedding\"] = df.combined.apply(lambda x: get_embedding(x, engine=embedding_model))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df.to_csv(\"data/weather_district_id_embeddings.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import cosine_similarity\n",
    "\n",
    "# 将城市名称进行embedding，通过余弦相似度匹配城市唯一标识\n",
    "def search_district_id(df, city_name):\n",
    "    if not city_name:\n",
    "        raise Exception(\"查询城市唯一标识参数异常\")\n",
    "    city_name = translate_city_to_eg(city_name)\n",
    "    product_embedding = get_embedding(city_name,engine=embedding_model)\n",
    "    df[\"similarity\"] = df.embedding.apply(lambda x: cosine_similarity(x, product_embedding))\n",
    "\n",
    "    return df.sort_values(\"similarity\", ascending=False).head(1)['district_geocode'].values[0]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(search_district_id(df, \"Shanghai, China\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 只获取当前天气\n",
    "# 第一个字典定义了一个名为\"get_current_weather\"的功能\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",  # 功能的名称\n",
    "        \"description\": \"Get the current weather\",  # 功能的描述\n",
    "        \"parameters\": {  # 定义该功能需要的参数\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {  # 参数的属性\n",
    "                \"location\": {  # 地点参数\n",
    "                    \"type\": \"string\",  # 参数类型为字符串\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",  # 参数的描述\n",
    "                },\n",
    "                \"format\": {  # 温度单位参数\n",
    "                    \"type\": \"string\",  # 参数类型为字符串\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],  # 参数的取值范围\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",  # 参数的描述\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\"],  # 该功能需要的必要参数\n",
    "        },\n",
    "    }\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "这段代码首先定义了一个`messages`列表用来存储聊天的消息，然后向列表中添加了系统和用户的消息。\n",
    "\n",
    "然后，它使用了之前定义的`chat_completion_request`函数发送一个请求，传入的参数包括消息列表和函数列表。\n",
    "\n",
    "在接收到响应后，它从JSON响应中解析出助手的消息，并将其添加到消息列表中。\n",
    "\n",
    "最后，它打印出 GPT 模型回复的消息。\n",
    "\n",
    "**（如果我们询问当前天气，GPT 模型会回复让你给出更准确的问题。）**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 定义一个空列表messages，用于存储聊天的内容\n",
    "messages = []\n",
    "\n",
    "# 使用append方法向messages列表添加一条系统角色的消息\n",
    "messages.append({\n",
    "    \"role\": \"system\",  # 消息的角色是\"system\"\n",
    "    \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"  # 消息的内容\n",
    "})\n",
    "\n",
    "# 向messages列表添加一条用户角色的消息\n",
    "messages.append({\n",
    "    \"role\": \"user\",  # 消息的角色是\"user\"\n",
    "    \"content\": \"What's the weather like today\"  # 用户询问今天的天气情况\n",
    "})\n",
    "\n",
    "# 使用定义的chat_completion_request函数发起一个请求，传入messages和functions作为参数\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions\n",
    ")\n",
    "\n",
    "# 解析返回的JSON数据，获取助手的回复消息\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "\n",
    "# 将助手的回复消息添加到messages列表中\n",
    "messages.append(assistant_message)\n",
    "\n",
    "pretty_print_conversation(messages)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(我们需要提供更详细的信息，以便于 GPT 模型为我们生成适当的函数和对应参数。)**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "type(assistant_message)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 使用 GPT 模型生成函数和对应参数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "下面这段代码先向messages列表中添加了用户的位置信息。\n",
    "\n",
    "然后再次使用了chat_completion_request函数发起请求，只是这次传入的消息列表已经包括了用户的新消息。\n",
    "\n",
    "在获取到响应后，它同样从JSON响应中解析出助手的消息，并将其添加到消息列表中。\n",
    "\n",
    "最后，打印出助手的新的回复消息。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 向messages列表添加一条用户角色的消息，用户告知他们在苏格兰的格拉斯哥\n",
    "messages.append({\n",
    "    \"role\": \"user\",  # 消息的角色是\"user\"\n",
    "    \"content\": \"我不告诉你\"  # 用户的消息内容\n",
    "})\n",
    "\n",
    "# 再次使用定义的chat_completion_request函数发起一个请求，传入更新后的messages和functions作为参数\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions\n",
    ")\n",
    "\n",
    "# 解析返回的JSON数据，获取助手的新的回复消息\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "\n",
    "if assistant_message[\"role\"] == \"assistant\" and assistant_message.get(\"function_call\"):\n",
    "    city_name = ast.literal_eval(assistant_message[\"function_call\"][\"arguments\"])[\"location\"]\n",
    "    district_id = search_district_id(df, city_name)\n",
    "    print(weather_request(district_id))\n",
    "\n",
    "\n",
    "# 将助手的新的回复消息添加到messages列表中\n",
    "# messages.append(assistant_message)\n",
    "\n",
    "pretty_print_conversation(messages)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
